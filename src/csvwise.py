#!/usr/bin/env python3
"""
csvwise - AI-Powered CSV Data Analyst CLI
Ask questions about your CSV data in natural language.

Enhanced v0.2.0 â€” Added smart diagnostics, outlier detection,
data quality scoring, visualization recommendations, and more.
"""

import argparse
import csv
import io
import json
import logging
import math
import os
import re
import subprocess
import sys
import tempfile
import time
from datetime import datetime
from pathlib import Path

# ---------------------------------------------------------------------------
# Constants
# ---------------------------------------------------------------------------
VERSION = "0.2.0"
MAX_PREVIEW_ROWS = 20          # rows sent to LLM for schema understanding
MAX_ANALYSIS_ROWS = 200        # rows sent for deep analysis
MAX_CELL_LEN = 200             # truncate long cell values
STATE_DIR = Path.home() / ".csvwise"
HISTORY_FILE = STATE_DIR / "history.json"
LOG_FILE = STATE_DIR / "csvwise.log"

LLM_TIMEOUT = 90               # default LLM timeout seconds
LLM_MAX_RETRIES = 2            # max retry attempts for LLM calls
LLM_RETRY_DELAY = 3            # seconds between retries

# Advanced type detection patterns
PATTERNS = {
    "email": re.compile(r"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z]{2,}$"),
    "url": re.compile(r"^https?://\S+$"),
    "phone": re.compile(r"^[\+]?[\d\s\-\(\)]{7,15}$"),
    "percentage": re.compile(r"^-?\d+\.?\d*\s*%$"),
    "currency_cny": re.compile(r"^Â¥[\d,]+\.?\d*$"),
    "currency_usd": re.compile(r"^\$[\d,]+\.?\d*$"),
    "boolean": re.compile(r"^(true|false|yes|no|æ˜¯|å¦|1|0)$", re.IGNORECASE),
    "ip_address": re.compile(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$"),
}

DATE_FORMATS = (
    "%Y-%m-%d", "%Y/%m/%d", "%m/%d/%Y", "%d/%m/%Y",
    "%Y-%m-%d %H:%M:%S", "%Y-%m-%dT%H:%M:%S",
    "%Yå¹´%mæœˆ%dæ—¥", "%m-%d-%Y",
)

# ---------------------------------------------------------------------------
# Logging
# ---------------------------------------------------------------------------

def setup_logging(verbose: bool = False):
    """Configure logging to file and optionally to stderr."""
    ensure_state_dir()
    handlers = [logging.FileHandler(LOG_FILE, encoding="utf-8")]
    if verbose:
        handlers.append(logging.StreamHandler(sys.stderr))
    logging.basicConfig(
        level=logging.DEBUG if verbose else logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
        handlers=handlers,
    )

logger = logging.getLogger("csvwise")

# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def ensure_state_dir():
    STATE_DIR.mkdir(parents=True, exist_ok=True)


def load_csv(path: str):
    """Load CSV and return (headers, rows, delimiter) with robust validation."""
    p = Path(path)
    if not p.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        sys.exit(1)
    if not p.is_file():
        print(f"âŒ ä¸æ˜¯æ–‡ä»¶: {path}")
        sys.exit(1)
    if p.stat().st_size == 0:
        print(f"âŒ æ–‡ä»¶ä¸ºç©º: {path}")
        sys.exit(1)
    if p.suffix.lower() not in (".csv", ".tsv", ".txt"):
        print(f"âš ï¸  æ–‡ä»¶ç±»å‹ {p.suffix} å¯èƒ½ä¸æ˜¯ CSVï¼Œå°è¯•åŠ è½½ä¸­...")

    logger.info("Loading CSV: %s (%.1f KB)", path, p.stat().st_size / 1024)

    # Detect encoding
    encodings = ["utf-8", "utf-8-sig", "gbk", "gb2312", "latin-1"]
    raw = p.read_bytes()
    text = None
    used_encoding = None
    for enc in encodings:
        try:
            text = raw.decode(enc)
            used_encoding = enc
            break
        except (UnicodeDecodeError, LookupError):
            continue
    if text is None:
        print("âŒ æ— æ³•è§£ç æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ç¼–ç ")
        sys.exit(1)

    logger.info("Detected encoding: %s", used_encoding)

    # Detect delimiter
    sniffer = csv.Sniffer()
    try:
        dialect = sniffer.sniff(text[:4096])
        delimiter = dialect.delimiter
    except csv.Error:
        delimiter = "," if "," in text[:1024] else "\t"

    reader = csv.reader(io.StringIO(text), delimiter=delimiter)
    rows = list(reader)

    # Filter out completely empty rows
    rows = [r for r in rows if any(cell.strip() for cell in r)]

    if len(rows) < 2:
        print("âŒ CSV æ–‡ä»¶è‡³å°‘éœ€è¦è¡¨å¤´ + 1è¡Œæ•°æ®")
        sys.exit(1)

    headers = rows[0]
    data = rows[1:]
    logger.info("Loaded %d rows, %d columns, delimiter=%r", len(data), len(headers), delimiter)
    return headers, data, delimiter


def truncate(s, maxlen=MAX_CELL_LEN):
    """Truncate string to maxlen, adding '...' if needed."""
    s = str(s).strip()
    return s[:maxlen] + "..." if len(s) > maxlen else s


def csv_to_markdown_table(headers, rows, max_rows=None):
    """Convert CSV rows to markdown table string."""
    if max_rows:
        rows = rows[:max_rows]
    lines = []
    lines.append("| " + " | ".join(headers) + " |")
    lines.append("| " + " | ".join(["---"] * len(headers)) + " |")
    for row in rows:
        # Pad or truncate row to match header count
        padded = row + [""] * (len(headers) - len(row))
        padded = padded[:len(headers)]
        lines.append("| " + " | ".join(truncate(c) for c in padded) + " |")
    return "\n".join(lines)


def infer_column_types(headers, data):
    """Infer column types by sampling data. Returns dict of headerâ†’type."""
    types = {}
    sample_size = min(len(data), 50)

    for col_idx, h in enumerate(headers):
        nums = 0
        dates = 0
        empties = 0
        pattern_counts = {k: 0 for k in PATTERNS}
        total = sample_size

        for row in data[:sample_size]:
            if col_idx >= len(row) or not row[col_idx].strip():
                empties += 1
                continue
            val = row[col_idx].strip()

            # Try number
            try:
                float(val.replace(",", "").replace("%", "").replace("Â¥", "").replace("$", ""))
                nums += 1
                continue
            except ValueError:
                pass

            # Try date
            is_date = False
            for fmt in DATE_FORMATS:
                try:
                    datetime.strptime(val, fmt)
                    dates += 1
                    is_date = True
                    break
                except ValueError:
                    continue

            if is_date:
                continue

            # Try advanced patterns
            for pname, pat in PATTERNS.items():
                if pat.match(val):
                    pattern_counts[pname] += 1
                    break

        non_empty = total - empties
        if non_empty == 0:
            types[h] = "empty"
        elif nums / max(non_empty, 1) > 0.7:
            types[h] = "numeric"
        elif dates / max(non_empty, 1) > 0.5:
            types[h] = "date"
        else:
            # Check advanced patterns
            best_pattern = max(pattern_counts, key=pattern_counts.get)
            if pattern_counts[best_pattern] / max(non_empty, 1) > 0.5:
                types[h] = best_pattern
            else:
                types[h] = "text"

    return types


def infer_advanced_types(headers, data):
    """Extended type inference with cardinality and uniqueness info."""
    types = infer_column_types(headers, data)
    details = {}

    for col_idx, h in enumerate(headers):
        values = [row[col_idx].strip() for row in data if col_idx < len(row) and row[col_idx].strip()]
        unique_count = len(set(values))
        total = len(values)

        detail = {
            "type": types[h],
            "total": len(data),
            "non_empty": total,
            "empty": len(data) - total,
            "empty_pct": round((len(data) - total) / max(len(data), 1) * 100, 1),
            "unique": unique_count,
            "cardinality": "high" if unique_count > total * 0.8 else ("medium" if unique_count > total * 0.2 else "low"),
        }

        # For categorical (low cardinality text), list unique values
        if detail["cardinality"] == "low" and types[h] == "text" and unique_count <= 20:
            from collections import Counter
            counter = Counter(values)
            detail["value_counts"] = dict(counter.most_common(10))

        details[h] = detail

    return types, details


def compute_basic_stats(headers, data, col_types):
    """Compute basic statistics for numeric columns."""
    stats = {}
    for col_idx, h in enumerate(headers):
        if col_types.get(h) != "numeric":
            continue
        values = []
        for row in data:
            if col_idx < len(row) and row[col_idx].strip():
                try:
                    values.append(float(row[col_idx].strip().replace(",", "").replace("%", "").replace("Â¥", "").replace("$", "")))
                except ValueError:
                    pass
        if not values:
            continue
        values.sort()
        n = len(values)
        mean = sum(values) / n
        variance = sum((v - mean) ** 2 for v in values) / max(n - 1, 1)
        std_dev = math.sqrt(variance)
        q1 = values[n // 4] if n >= 4 else values[0]
        q3 = values[(3 * n) // 4] if n >= 4 else values[-1]
        iqr = q3 - q1

        stats[h] = {
            "count": n,
            "min": round(values[0], 4),
            "max": round(values[-1], 4),
            "mean": round(mean, 4),
            "median": round(values[n // 2], 4),
            "sum": round(sum(values), 4),
            "std_dev": round(std_dev, 4),
            "q1": round(q1, 4),
            "q3": round(q3, 4),
            "iqr": round(iqr, 4),
        }
    return stats


def detect_outliers(headers, data, col_types, stats=None):
    """Detect outliers using IQR method. Returns dict of headerâ†’outlier_info."""
    if stats is None:
        stats = compute_basic_stats(headers, data, col_types)

    outliers = {}
    for col_idx, h in enumerate(headers):
        if h not in stats or stats[h]["iqr"] == 0:
            continue

        s = stats[h]
        q1, q3, iqr = s["q1"], s["q3"], s["iqr"]
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        outlier_values = []
        outlier_rows = []
        for row_idx, row in enumerate(data):
            if col_idx < len(row) and row[col_idx].strip():
                try:
                    v = float(row[col_idx].strip().replace(",", "").replace("%", "").replace("Â¥", "").replace("$", ""))
                    if v < lower_bound or v > upper_bound:
                        outlier_values.append(v)
                        outlier_rows.append(row_idx + 2)  # +2 for header + 1-indexed
                except ValueError:
                    pass

        if outlier_values:
            outliers[h] = {
                "count": len(outlier_values),
                "percentage": round(len(outlier_values) / s["count"] * 100, 1),
                "lower_bound": round(lower_bound, 4),
                "upper_bound": round(upper_bound, 4),
                "values": outlier_values[:10],  # first 10
                "rows": outlier_rows[:10],
            }

    return outliers


def compute_data_quality_score(headers, data, col_types, type_details=None):
    """Compute an overall data quality score (0-100)."""
    if type_details is None:
        _, type_details = infer_advanced_types(headers, data)

    scores = {
        "completeness": 100,
        "consistency": 100,
        "validity": 100,
    }

    # Completeness: penalize empty values
    total_cells = len(headers) * len(data)
    empty_cells = sum(d["empty"] for d in type_details.values())
    if total_cells > 0:
        scores["completeness"] = round((1 - empty_cells / total_cells) * 100, 1)

    # Consistency: check if columns have consistent types
    inconsistent = 0
    for col_idx, h in enumerate(headers):
        if col_types.get(h) == "numeric":
            non_numeric = 0
            total = 0
            for row in data:
                if col_idx < len(row) and row[col_idx].strip():
                    total += 1
                    try:
                        float(row[col_idx].strip().replace(",", "").replace("%", "").replace("Â¥", "").replace("$", ""))
                    except ValueError:
                        non_numeric += 1
            if total > 0 and non_numeric / total > 0.1:
                inconsistent += 1
    if headers:
        scores["consistency"] = round((1 - inconsistent / len(headers)) * 100, 1)

    # Validity: check row length consistency
    expected_cols = len(headers)
    bad_rows = sum(1 for row in data if len(row) != expected_cols)
    if data:
        scores["validity"] = round((1 - bad_rows / len(data)) * 100, 1)

    overall = round(sum(scores.values()) / len(scores), 1)
    return {**scores, "overall": overall}


def suggest_visualizations(headers, col_types, stats, data):
    """Suggest appropriate chart types based on data characteristics."""
    suggestions = []

    numeric_cols = [h for h in headers if col_types.get(h) == "numeric"]
    date_cols = [h for h in headers if col_types.get(h) == "date"]
    text_cols = [h for h in headers if col_types.get(h) == "text"]

    # Time series
    if date_cols and numeric_cols:
        suggestions.append({
            "type": "æŠ˜çº¿å›¾ (Line Chart)",
            "x": date_cols[0],
            "y": numeric_cols[0],
            "reason": "æœ‰æ—¶é—´ç»´åº¦å’Œæ•°å€¼åˆ—ï¼Œé€‚åˆå±•ç¤ºè¶‹åŠ¿",
            "priority": "high",
        })

    # Distribution
    for col in numeric_cols[:2]:
        suggestions.append({
            "type": "ç›´æ–¹å›¾ (Histogram)",
            "column": col,
            "reason": f"å±•ç¤º {col} çš„åˆ†å¸ƒç‰¹å¾",
            "priority": "medium",
        })

    # Category comparison
    if text_cols and numeric_cols:
        unique_count = len(set(row[headers.index(text_cols[0])]
                              for row in data[:100]
                              if headers.index(text_cols[0]) < len(row)))
        if unique_count <= 15:
            suggestions.append({
                "type": "æŸ±çŠ¶å›¾ (Bar Chart)",
                "x": text_cols[0],
                "y": numeric_cols[0],
                "reason": f"æŒ‰ {text_cols[0]} åˆ†ç»„æ¯”è¾ƒ {numeric_cols[0]}",
                "priority": "high",
            })

        if unique_count <= 8 and len(numeric_cols) >= 1:
            suggestions.append({
                "type": "é¥¼å›¾ (Pie Chart)",
                "column": text_cols[0],
                "value": numeric_cols[0],
                "reason": f"å±•ç¤º {text_cols[0]} å„ç±»åˆ«åœ¨ {numeric_cols[0]} ä¸­çš„å æ¯”",
                "priority": "medium",
            })

    # Scatter plot for correlation
    if len(numeric_cols) >= 2:
        suggestions.append({
            "type": "æ•£ç‚¹å›¾ (Scatter Plot)",
            "x": numeric_cols[0],
            "y": numeric_cols[1],
            "reason": f"æ¢ç´¢ {numeric_cols[0]} ä¸ {numeric_cols[1]} çš„ç›¸å…³æ€§",
            "priority": "medium",
        })

    # Box plot for outlier visualization
    if numeric_cols:
        suggestions.append({
            "type": "ç®±çº¿å›¾ (Box Plot)",
            "columns": numeric_cols[:5],
            "reason": "ç›´è§‚å±•ç¤ºæ•°å€¼åˆ†å¸ƒå’Œå¼‚å¸¸å€¼",
            "priority": "low",
        })

    # Heatmap for multi-category
    if len(text_cols) >= 2 and numeric_cols:
        suggestions.append({
            "type": "çƒ­åŠ›å›¾ (Heatmap)",
            "row": text_cols[0],
            "col": text_cols[1],
            "value": numeric_cols[0],
            "reason": f"å±•ç¤º {text_cols[0]} Ã— {text_cols[1]} çš„ {numeric_cols[0]} åˆ†å¸ƒ",
            "priority": "low",
        })

    return suggestions


def build_schema_prompt(headers, data, col_types):
    """Build a schema description for the LLM."""
    lines = ["## æ•°æ®é›†æ¦‚è¦", f"- æ€»è¡Œæ•°: {len(data)}", f"- åˆ—æ•°: {len(headers)}", ""]
    lines.append("## åˆ—ä¿¡æ¯")
    for col_idx, h in enumerate(headers):
        t = col_types.get(h, "unknown")
        # Get sample unique values
        vals = set()
        for row in data[:100]:
            if col_idx < len(row) and row[col_idx].strip():
                vals.add(truncate(row[col_idx], 50))
            if len(vals) >= 5:
                break
        sample = ", ".join(list(vals)[:5])
        lines.append(f"- **{h}** (ç±»å‹: {t}) â€” ç¤ºä¾‹å€¼: {sample}")
    return "\n".join(lines)


# ---------------------------------------------------------------------------
# DataContext â€” eliminates repeated loading boilerplate
# ---------------------------------------------------------------------------

class DataContext:
    """Holds loaded CSV data with lazy-computed analytics."""

    def __init__(self, path: str):
        self.path = path
        self.headers, self.data, self.delimiter = load_csv(path)
        self._col_types = None
        self._type_details = None
        self._stats = None
        self._outliers = None
        self._quality = None
        self._viz_suggestions = None
        self._schema_prompt = None

    @property
    def col_types(self):
        if self._col_types is None:
            self._col_types = infer_column_types(self.headers, self.data)
        return self._col_types

    @property
    def type_details(self):
        if self._type_details is None:
            self._col_types, self._type_details = infer_advanced_types(self.headers, self.data)
        return self._type_details

    @property
    def stats(self):
        if self._stats is None:
            self._stats = compute_basic_stats(self.headers, self.data, self.col_types)
        return self._stats

    @property
    def outliers(self):
        if self._outliers is None:
            self._outliers = detect_outliers(self.headers, self.data, self.col_types, self.stats)
        return self._outliers

    @property
    def quality(self):
        if self._quality is None:
            self._quality = compute_data_quality_score(
                self.headers, self.data, self.col_types, self.type_details
            )
        return self._quality

    @property
    def viz_suggestions(self):
        if self._viz_suggestions is None:
            self._viz_suggestions = suggest_visualizations(
                self.headers, self.col_types, self.stats, self.data
            )
        return self._viz_suggestions

    @property
    def schema_prompt(self):
        if self._schema_prompt is None:
            self._schema_prompt = build_schema_prompt(
                self.headers, self.data, self.col_types
            )
        return self._schema_prompt

    def stats_text(self):
        """Format stats as text section for prompts."""
        if not self.stats:
            return ""
        lines = ["## åŸºç¡€ç»Ÿè®¡"]
        for h, s in self.stats.items():
            lines.append(
                f"- {h}: count={s['count']}, min={s['min']}, max={s['max']}, "
                f"mean={s['mean']}, median={s['median']}, sum={s['sum']}, "
                f"std_dev={s['std_dev']}"
            )
        return "\n".join(lines)

    def sample_table(self, max_rows=None):
        """Get markdown table of sample data."""
        n = max_rows or min(MAX_ANALYSIS_ROWS, len(self.data))
        return csv_to_markdown_table(self.headers, self.data, max_rows=n)

    def outliers_text(self):
        """Format outlier info as text section."""
        if not self.outliers:
            return ""
        lines = ["## å¼‚å¸¸å€¼æ£€æµ‹ (IQRæ–¹æ³•)"]
        for h, o in self.outliers.items():
            lines.append(
                f"- **{h}**: {o['count']}ä¸ªå¼‚å¸¸å€¼ ({o['percentage']}%), "
                f"èŒƒå›´ [{o['lower_bound']}, {o['upper_bound']}], "
                f"å¼‚å¸¸å€¼æ ·ä¾‹: {o['values'][:5]}"
            )
        return "\n".join(lines)

    def quality_text(self):
        """Format quality score as text."""
        q = self.quality
        lines = [
            "## æ•°æ®è´¨é‡è¯„åˆ†",
            f"- æ€»åˆ†: {q['overall']}/100",
            f"- å®Œæ•´æ€§: {q['completeness']}/100",
            f"- ä¸€è‡´æ€§: {q['consistency']}/100",
            f"- æœ‰æ•ˆæ€§: {q['validity']}/100",
        ]
        return "\n".join(lines)


# ---------------------------------------------------------------------------
# LLM Integration
# ---------------------------------------------------------------------------

def llm_query(prompt: str, timeout: int = LLM_TIMEOUT, retries: int = LLM_MAX_RETRIES) -> str:
    """Call gemini CLI for LLM inference with retry logic."""
    last_error = ""
    for attempt in range(1, retries + 1):
        try:
            logger.info("LLM query attempt %d/%d (prompt length: %d chars)", attempt, retries, len(prompt))
            result = subprocess.run(
                ["gemini", prompt],
                capture_output=True,
                text=True,
                timeout=timeout,
            )
            if result.returncode == 0 and result.stdout.strip():
                logger.info("LLM query succeeded (response length: %d chars)", len(result.stdout))
                return result.stdout.strip()

            # Fallback: try with stdin
            result2 = subprocess.run(
                ["gemini"],
                input=prompt,
                capture_output=True,
                text=True,
                timeout=timeout,
            )
            if result2.returncode == 0 and result2.stdout.strip():
                logger.info("LLM query succeeded via stdin (response length: %d chars)", len(result2.stdout))
                return result2.stdout.strip()

            last_error = result.stderr[:200] or result2.stderr[:200] or "empty response"
            logger.warning("LLM attempt %d failed: %s", attempt, last_error)

        except FileNotFoundError:
            return "âŒ æœªæ‰¾åˆ° gemini CLIã€‚è¯·å®‰è£…: npm i -g @anthropic-ai/gemini-cli"
        except subprocess.TimeoutExpired:
            last_error = "timeout"
            logger.warning("LLM attempt %d timed out after %ds", attempt, timeout)

        if attempt < retries:
            delay = LLM_RETRY_DELAY * attempt
            logger.info("Retrying in %ds...", delay)
            time.sleep(delay)

    return f"âŒ LLM è°ƒç”¨å¤±è´¥ (é‡è¯•{retries}æ¬¡): {last_error}"


def save_history(action: str, file: str, query: str, result_preview: str):
    """Save query history."""
    ensure_state_dir()
    history = []
    if HISTORY_FILE.exists():
        try:
            history = json.loads(HISTORY_FILE.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, IOError):
            logger.warning("Failed to load history, starting fresh")
            history = []
    history.append({
        "timestamp": datetime.now().isoformat(),
        "action": action,
        "file": str(file),
        "query": query,
        "result_preview": result_preview[:200],
    })
    # Keep last 100 entries
    history = history[-100:]
    HISTORY_FILE.write_text(json.dumps(history, ensure_ascii=False, indent=2), encoding="utf-8")


# ---------------------------------------------------------------------------
# Commands
# ---------------------------------------------------------------------------

def cmd_info(args):
    """Show dataset information with enhanced diagnostics."""
    ctx = DataContext(args.file)

    print(f"\nğŸ“Š æ•°æ®é›†: {args.file}")
    print(f"   è¡Œæ•°: {len(ctx.data):,}  |  åˆ—æ•°: {len(ctx.headers)}  |  åˆ†éš”ç¬¦: {repr(ctx.delimiter)}")

    # Quality score
    q = ctx.quality
    quality_emoji = "ğŸŸ¢" if q["overall"] >= 80 else ("ğŸŸ¡" if q["overall"] >= 60 else "ğŸ”´")
    print(f"   æ•°æ®è´¨é‡: {quality_emoji} {q['overall']}/100 (å®Œæ•´æ€§:{q['completeness']} ä¸€è‡´æ€§:{q['consistency']} æœ‰æ•ˆæ€§:{q['validity']})")
    print()

    # Column info with advanced types
    print("ğŸ“‹ åˆ—ä¿¡æ¯:")
    details = ctx.type_details
    for h in ctx.headers:
        t = ctx.col_types.get(h, "unknown")
        d = details.get(h, {})
        emoji = {
            "numeric": "ğŸ”¢", "date": "ğŸ“…", "text": "ğŸ“", "empty": "â¬œ",
            "email": "ğŸ“§", "url": "ğŸ”—", "phone": "ğŸ“±", "percentage": "ğŸ’¯",
            "currency_cny": "ğŸ’°", "currency_usd": "ğŸ’µ", "boolean": "âœ…",
            "ip_address": "ğŸŒ",
        }.get(t, "â“")

        line = f"   {emoji} {h} ({t})"

        # Add cardinality info
        if d:
            empty_str = f"  ç©ºå€¼:{d['empty']}({d['empty_pct']}%)" if d["empty"] > 0 else ""
            line += f"  [{d['cardinality']}åŸºæ•°, {d['unique']}ç§]{empty_str}"

        # Add stats for numeric
        if h in ctx.stats:
            s = ctx.stats[h]
            line += f"  â€” min={s['min']}, max={s['max']}, mean={s['mean']}, std={s['std_dev']}"

        print(line)

    # Outlier summary
    if ctx.outliers:
        print(f"\nâš ï¸  å¼‚å¸¸å€¼æ£€æµ‹:")
        for h, o in ctx.outliers.items():
            print(f"   ğŸ“ {h}: {o['count']}ä¸ªå¼‚å¸¸å€¼ ({o['percentage']}%) â€” æ­£å¸¸èŒƒå›´ [{o['lower_bound']}, {o['upper_bound']}]")

    # Preview
    print(f"\nğŸ“ƒ å‰ {min(5, len(ctx.data))} è¡Œé¢„è§ˆ:")
    print(csv_to_markdown_table(ctx.headers, ctx.data, max_rows=5))

    # Visualization suggestions
    if ctx.viz_suggestions:
        print(f"\nğŸ’¡ æ¨èå¯è§†åŒ–:")
        for i, s in enumerate(ctx.viz_suggestions[:3], 1):
            print(f"   {i}. {s['type']} â€” {s['reason']}")

    print()


def cmd_ask(args):
    """Ask a natural language question about the data."""
    ctx = DataContext(args.file)

    sample_rows = min(MAX_ANALYSIS_ROWS, len(ctx.data))
    table = ctx.sample_table(sample_rows)

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹ CSV æ•°æ®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

{ctx.schema_prompt}

{ctx.stats_text()}

{ctx.outliers_text()}

## æ•°æ®æ ·æœ¬ (å‰ {sample_rows} è¡Œï¼Œå…± {len(ctx.data)} è¡Œ)
{table}

## ç”¨æˆ·é—®é¢˜
{args.question}

## å›ç­”è¦æ±‚
1. ç”¨ä¸­æ–‡å›ç­”
2. ç»™å‡ºå…·ä½“æ•°æ®å’Œè®¡ç®—è¿‡ç¨‹
3. å¦‚æœéœ€è¦ï¼Œç”¨ markdown è¡¨æ ¼å±•ç¤ºç»“æœ
4. æŒ‡å‡ºæ•°æ®ä¸­çš„æœ‰è¶£å‘ç°
5. å¦‚æœæ•°æ®ä¸è¶³ä»¥å›ç­”ï¼Œè¯´æ˜åŸå› å¹¶å»ºè®®éœ€è¦ä»€ä¹ˆé¢å¤–æ•°æ®"""

    print(f"\nğŸ¤” åˆ†æä¸­: {args.question}")
    print("â”€" * 60)
    result = llm_query(prompt, timeout=90)
    print(result)
    print("â”€" * 60)

    save_history("ask", args.file, args.question, result)


def cmd_report(args):
    """Generate a comprehensive analysis report with AI-enhanced insights."""
    ctx = DataContext(args.file)

    sample_rows = min(MAX_ANALYSIS_ROWS, len(ctx.data))
    table = ctx.sample_table(sample_rows)

    # Build enhanced prompt with all analytics
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±æ•°æ®åˆ†æå¸ˆã€‚è¯·å¯¹ä»¥ä¸‹ CSV æ•°æ®ç”Ÿæˆä¸€ä»½å…¨é¢çš„åˆ†ææŠ¥å‘Šã€‚

{ctx.schema_prompt}

{ctx.stats_text()}

{ctx.outliers_text()}

{ctx.quality_text()}

## æ•°æ®æ ·æœ¬ (å‰ {sample_rows} è¡Œï¼Œå…± {len(ctx.data)} è¡Œ)
{table}

## æŠ¥å‘Šè¦æ±‚
è¯·ç”Ÿæˆä»¥ä¸‹ç« èŠ‚çš„è¯¦ç»†æŠ¥å‘Šï¼ˆä¸­æ–‡ï¼‰ï¼š

### 1. ğŸ“Š æ•°æ®æ¦‚è§ˆ
- æ•°æ®é›†å¤§å°ã€å®Œæ•´æ€§ã€è´¨é‡è¯„ä¼°
- æ•°æ®è´¨é‡å¾—åˆ†è§£è¯»

### 2. ğŸ“ˆ å…³é”®å‘ç°
- æœ€é‡è¦çš„ 3-5 ä¸ªå‘ç°
- ç”¨å…·ä½“æ•°æ®æ”¯æ’‘

### 3. ğŸ“‰ è¶‹åŠ¿ä¸æ¨¡å¼
- æ•°æ®ä¸­çš„è¶‹åŠ¿ï¼ˆå¦‚æœ‰æ—¶é—´ç»´åº¦ï¼‰
- åˆ†å¸ƒç‰¹å¾
- å¼‚å¸¸å€¼åˆ†æï¼ˆå‚è€ƒä¸Šæ–¹å¼‚å¸¸å€¼æ£€æµ‹ç»“æœï¼‰

### 4. ğŸ”— å…³è”åˆ†æ
- åˆ—ä¹‹é—´çš„å…³ç³»
- æœ‰æ„ä¹‰çš„åˆ†ç»„å¯¹æ¯”

### 5. ğŸ§¹ æ•°æ®æ¸…æ´—å»ºè®®
- åŸºäºè´¨é‡è¯„åˆ†çš„æ”¹è¿›å»ºè®®
- ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥
- å¼‚å¸¸å€¼å¤„ç†å»ºè®®

### 6. ğŸ“Š å¯è§†åŒ–å»ºè®®
- æ¨èçš„å›¾è¡¨ç±»å‹åŠç†ç”±
- å…·ä½“çš„å¯è§†åŒ–æ–¹æ¡ˆ

### 7. ğŸ’¡ å»ºè®®ä¸æ´å¯Ÿ
- åŸºäºæ•°æ®çš„å¯è¡Œå»ºè®®
- éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥çš„æ–¹å‘

### 8. âš ï¸ æ•°æ®å±€é™æ€§
- æ•°æ®çš„ä¸è¶³ä¹‹å¤„
- æ”¹è¿›å»ºè®®

ç”¨ markdown æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«è¡¨æ ¼å’Œåˆ—è¡¨ã€‚"""

    print(f"\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š: {args.file}")
    print("â•" * 60)
    result = llm_query(prompt, timeout=120)
    print(result)
    print("â•" * 60)

    # Save report
    if args.output:
        out_path = Path(args.output)
        report_content = f"# æ•°æ®åˆ†ææŠ¥å‘Š: {args.file}\n\n"
        report_content += f"_ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_\n\n"
        report_content += f"_csvwise v{VERSION} â€” AI-Powered CSV Data Analyst_\n\n"

        # Add local analytics section
        report_content += "---\n\n## ğŸ“Š è‡ªåŠ¨åŒ–åˆ†ææ‘˜è¦\n\n"
        report_content += f"| æŒ‡æ ‡ | å€¼ |\n|------|------|\n"
        report_content += f"| æ€»è¡Œæ•° | {len(ctx.data):,} |\n"
        report_content += f"| æ€»åˆ—æ•° | {len(ctx.headers)} |\n"
        q = ctx.quality
        report_content += f"| æ•°æ®è´¨é‡åˆ† | {q['overall']}/100 |\n"
        report_content += f"| å®Œæ•´æ€§ | {q['completeness']}/100 |\n"
        report_content += f"| ä¸€è‡´æ€§ | {q['consistency']}/100 |\n"
        report_content += f"| æœ‰æ•ˆæ€§ | {q['validity']}/100 |\n\n"

        if ctx.outliers:
            report_content += "### å¼‚å¸¸å€¼æ£€æµ‹\n\n"
            for h, o in ctx.outliers.items():
                report_content += f"- **{h}**: {o['count']}ä¸ª ({o['percentage']}%)\n"
            report_content += "\n"

        report_content += "---\n\n## AI æ·±åº¦åˆ†æ\n\n"
        report_content += result
        out_path.write_text(report_content, encoding="utf-8")
        print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜: {out_path}")

    save_history("report", args.file, "full_report", result)


def cmd_clean(args):
    """AI-suggested data cleaning recommendations with quality scoring."""
    ctx = DataContext(args.file)

    # Quality analysis
    quality_lines = ["## æ•°æ®è´¨é‡è¯¦ç»†æ£€æŸ¥"]
    details = ctx.type_details
    for h, d in details.items():
        flags = []
        if d["empty_pct"] > 5:
            flags.append(f"âš ï¸ ç©ºå€¼ {d['empty']}ä¸ª ({d['empty_pct']}%)")
        if d["cardinality"] == "low" and d["type"] == "text" and d.get("value_counts"):
            top = list(d["value_counts"].items())[:3]
            flags.append(f"ğŸ“Š ä¸»è¦å€¼: {', '.join(f'{k}({v})' for k,v in top)}")
        flag_str = " | ".join(flags) if flags else "âœ…"
        quality_lines.append(f"- {h} [{d['type']}]: {flag_str}")

    quality_text = "\n".join(quality_lines)
    table = ctx.sample_table(20)

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®æ¸…æ´—ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ•°æ®é›†çš„è´¨é‡é—®é¢˜å¹¶ç»™å‡ºæ¸…æ´—å»ºè®®ã€‚

{ctx.schema_prompt}

{quality_text}

{ctx.quality_text()}

{ctx.outliers_text()}

## æ•°æ®æ ·æœ¬
{table}

## è¯·è¾“å‡º
1. ğŸ” **å‘ç°çš„é—®é¢˜** â€” ç©ºå€¼ã€å¼‚å¸¸å€¼ã€æ ¼å¼ä¸ä¸€è‡´ã€ç¼–ç é—®é¢˜ç­‰
2. ğŸ› ï¸ **æ¸…æ´—å»ºè®®** â€” å…·ä½“çš„å¤„ç†æ–¹æ¡ˆï¼ˆå¡«å……ç­–ç•¥ã€åˆ é™¤ç­–ç•¥ã€æ ¼å¼æ ‡å‡†åŒ–ç­‰ï¼‰
3. ğŸ“Š **æ¸…æ´—åé¢„æœŸæ•ˆæœ** â€” æ•°æ®è´¨é‡æå‡é¢„ä¼°ï¼ˆç›®æ ‡åˆ†æ•°ï¼‰
4. ğŸ **Python ä»£ç ç‰‡æ®µ** â€” å¯ç›´æ¥è¿è¡Œçš„ pandas æ¸…æ´—ä»£ç 

ç”¨ä¸­æ–‡å›ç­”ã€‚"""

    print(f"\nğŸ§¹ æ•°æ®è´¨é‡åˆ†æ: {args.file}")
    q = ctx.quality
    quality_emoji = "ğŸŸ¢" if q["overall"] >= 80 else ("ğŸŸ¡" if q["overall"] >= 60 else "ğŸ”´")
    print(f"   å½“å‰è´¨é‡åˆ†: {quality_emoji} {q['overall']}/100")
    print("â”€" * 60)
    result = llm_query(prompt, timeout=90)
    print(result)
    print("â”€" * 60)

    save_history("clean", args.file, "clean_analysis", result)


def cmd_diagnose(args):
    """Full AI-powered data diagnosis â€” combines outlier detection, quality scoring, and smart suggestions."""
    ctx = DataContext(args.file)

    print(f"\nğŸ”¬ æ•°æ®è¯Šæ–­: {args.file}")
    print("â•" * 60)

    # 1. Data Quality Score
    q = ctx.quality
    quality_emoji = "ğŸŸ¢" if q["overall"] >= 80 else ("ğŸŸ¡" if q["overall"] >= 60 else "ğŸ”´")
    print(f"\nğŸ“Š æ•°æ®è´¨é‡è¯„åˆ†: {quality_emoji} {q['overall']}/100")
    print(f"   å®Œæ•´æ€§: {q['completeness']}  |  ä¸€è‡´æ€§: {q['consistency']}  |  æœ‰æ•ˆæ€§: {q['validity']}")

    # 2. Column Diagnostics
    print(f"\nğŸ“‹ åˆ—è¯Šæ–­:")
    details = ctx.type_details
    for h in ctx.headers:
        d = details.get(h, {})
        t = ctx.col_types.get(h, "?")
        status = "ğŸŸ¢" if d.get("empty_pct", 0) < 5 else ("ğŸŸ¡" if d.get("empty_pct", 0) < 20 else "ğŸ”´")
        print(f"   {status} {h}: type={t}, unique={d.get('unique','?')}, empty={d.get('empty_pct',0)}%", end="")
        if h in ctx.stats:
            s = ctx.stats[h]
            print(f", range=[{s['min']}, {s['max']}], Ïƒ={s['std_dev']}", end="")
        print()

    # 3. Outlier Report
    if ctx.outliers:
        print(f"\nâš ï¸  å¼‚å¸¸å€¼æ£€æµ‹ (IQRæ–¹æ³•):")
        for h, o in ctx.outliers.items():
            print(f"   ğŸ“ {h}: {o['count']}ä¸ªå¼‚å¸¸å€¼ ({o['percentage']}%)")
            print(f"      æ­£å¸¸èŒƒå›´: [{o['lower_bound']}, {o['upper_bound']}]")
            print(f"      å¼‚å¸¸å€¼æ ·ä¾‹: {o['values'][:5]}")
    else:
        print(f"\nâœ… æœªæ£€æµ‹åˆ°æ˜¾è‘—å¼‚å¸¸å€¼")

    # 4. Visualization Recommendations
    if ctx.viz_suggestions:
        print(f"\nğŸ“Š å¯è§†åŒ–å»ºè®®:")
        for i, s in enumerate(ctx.viz_suggestions[:5], 1):
            priority_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(s.get("priority", ""), "âšª")
            print(f"   {i}. {priority_emoji} {s['type']} â€” {s['reason']}")

    # 5. AI Deep Diagnosis
    sample_rows = min(50, len(ctx.data))
    table = ctx.sample_table(sample_rows)

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®ç§‘å­¦å®¶ã€‚è¯·å¯¹ä»¥ä¸‹æ•°æ®é›†è¿›è¡Œæ·±åº¦è¯Šæ–­ï¼Œç»™å‡ºä¸“ä¸šå»ºè®®ã€‚

{ctx.schema_prompt}

{ctx.stats_text()}

{ctx.outliers_text()}

{ctx.quality_text()}

## æ•°æ®æ ·æœ¬ (å‰ {sample_rows} è¡Œ)
{table}

## è¯·ç»™å‡ºç®€æ´çš„è¯Šæ–­æ„è§
1. **æ•°æ®å¥åº·åº¦** â€” ä¸€å¥è¯æ€»ç»“
2. **æœ€å…³é”®çš„3ä¸ªé—®é¢˜** â€” å¦‚æœ‰
3. **å¿«é€Ÿæ”¹è¿›å»ºè®®** â€” ç«‹å³å¯è¡Œçš„ 2-3 ä¸ªæ­¥éª¤
4. **æ·±å…¥åˆ†ææ–¹å‘** â€” å€¼å¾—æ¢ç´¢çš„ 2-3 ä¸ªæ–¹å‘

ç®€æ´ä¸ºä¸»ï¼Œæ¯ç‚¹ 1-2 å¥è¯ã€‚ä¸­æ–‡å›ç­”ã€‚"""

    print(f"\nğŸ¤– AI è¯Šæ–­æ„è§:")
    print("â”€" * 60)
    result = llm_query(prompt, timeout=60)
    print(result)
    print("â•" * 60)

    save_history("diagnose", args.file, "diagnose", result)


def cmd_plot(args):
    """Generate a Python matplotlib plotting script."""
    ctx = DataContext(args.file)

    # Include visualization suggestions in prompt
    viz_text = ""
    if ctx.viz_suggestions:
        viz_text = "## æ¨èçš„å¯è§†åŒ–ç±»å‹\n"
        for s in ctx.viz_suggestions[:3]:
            viz_text += f"- {s['type']}: {s['reason']}\n"

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®å¯è§†åŒ–ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„æè¿°ç”Ÿæˆ Python matplotlib ç»‘å›¾ä»£ç ã€‚

{ctx.schema_prompt}

{viz_text}

## ç”¨æˆ·è¦æ±‚
{args.description}

## ä»£ç è¦æ±‚
1. ä½¿ç”¨ pandas + matplotlib
2. ä¸­æ–‡æ ‡é¢˜å’Œæ ‡ç­¾ï¼ˆä½¿ç”¨ plt.rcParams è®¾ç½®ä¸­æ–‡å­—ä½“ï¼‰
3. ç¾è§‚çš„é…è‰²æ–¹æ¡ˆ
4. ä»£ç å¯ç›´æ¥è¿è¡Œ
5. è¯»å–æ–‡ä»¶è·¯å¾„: {os.path.abspath(args.file)}
6. ä¿å­˜å›¾ç‰‡åˆ°åŒç›®å½•
7. æ‰“å°ä¿å­˜è·¯å¾„

åªè¾“å‡º Python ä»£ç ï¼Œä¸è¦è§£é‡Šã€‚ç”¨ ```python ``` åŒ…è£¹ã€‚"""

    print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–ä»£ç ...")
    print("â”€" * 60)
    result = llm_query(prompt, timeout=60)

    # Extract code block
    code = result
    if "```python" in result:
        code = result.split("```python")[1].split("```")[0].strip()
    elif "```" in result:
        code = result.split("```")[1].split("```")[0].strip()

    if not code.strip():
        print("âŒ LLM æœªç”Ÿæˆæœ‰æ•ˆä»£ç ")
        return

    # Save script
    script_path = Path(args.file).parent / f"plot_{Path(args.file).stem}.py"
    script_path.write_text(code, encoding="utf-8")
    print(f"ğŸ“ ç»˜å›¾è„šæœ¬å·²ä¿å­˜: {script_path}")

    if args.run:
        print("\nğŸš€ è¿è¡Œç»˜å›¾è„šæœ¬...")
        try:
            subprocess.run([sys.executable, str(script_path)], timeout=30, check=True)
            print("âœ… å›¾è¡¨ç”ŸæˆæˆåŠŸ!")
        except subprocess.CalledProcessError as e:
            print(f"âŒ è¿è¡Œå¤±è´¥: {e}")
        except subprocess.TimeoutExpired:
            print("âŒ è¿è¡Œè¶…æ—¶")
    else:
        print(f"ğŸ’¡ è¿è¡Œ: python {script_path}")

    print("â”€" * 60)
    save_history("plot", args.file, args.description, code[:200])


def cmd_query(args):
    """Execute a SQL-like query on the CSV (via pandas)."""
    ctx = DataContext(args.file)

    prompt = f"""ä½ æ˜¯ä¸€ä¸ª Python pandas ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢éœ€æ±‚ç”Ÿæˆ pandas ä»£ç ã€‚

{ctx.schema_prompt}

## ç”¨æˆ·æŸ¥è¯¢
{args.sql}

## ä»£ç è¦æ±‚
1. è¯»å– CSV: pd.read_csv("{os.path.abspath(args.file)}")
2. æ‰§è¡ŒæŸ¥è¯¢
3. æ‰“å°ç»“æœï¼ˆç”¨ to_string() æˆ– to_markdown() æ ¼å¼åŒ–ï¼‰
4. å¦‚æœç»“æœæ˜¯æ•°å€¼ï¼Œç›´æ¥æ‰“å°
5. åªè¾“å‡ºå¯æ‰§è¡Œçš„ Python ä»£ç 
6. ä¸è¦ä½¿ç”¨ tabulateï¼ˆå¯èƒ½æœªå®‰è£…ï¼‰

åªè¾“å‡ºä»£ç ï¼Œç”¨ ```python ``` åŒ…è£¹ã€‚"""

    result = llm_query(prompt, timeout=60)

    code = result
    if "```python" in result:
        code = result.split("```python")[1].split("```")[0].strip()
    elif "```" in result:
        code = result.split("```")[1].split("```")[0].strip()

    if not code.strip():
        print("âŒ LLM æœªç”Ÿæˆæœ‰æ•ˆä»£ç ")
        return

    print(f"\nğŸ” æ‰§è¡ŒæŸ¥è¯¢: {args.sql}")
    print("â”€" * 60)

    # Execute the code in a temp file
    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False, encoding="utf-8") as f:
        f.write(code)
        tmp = f.name

    try:
        result = subprocess.run(
            [sys.executable, tmp],
            capture_output=True,
            text=True,
            timeout=30,
        )
        if result.stdout:
            print(result.stdout)
        if result.stderr:
            print(f"âš ï¸ {result.stderr[:300]}")
    except subprocess.TimeoutExpired:
        print("âŒ æŸ¥è¯¢æ‰§è¡Œè¶…æ—¶")
    finally:
        try:
            os.unlink(tmp)
        except OSError:
            pass

    print("â”€" * 60)
    save_history("query", args.file, args.sql, code[:200])


def cmd_compare(args):
    """Compare two CSV files."""
    ctx1 = DataContext(args.file1)
    ctx2 = DataContext(args.file2)

    table1 = ctx1.sample_table(10)
    table2 = ctx2.sample_table(10)

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æå¸ˆã€‚è¯·æ¯”è¾ƒä»¥ä¸‹ä¸¤ä¸ªæ•°æ®é›†å¹¶ç»™å‡ºè¯¦ç»†åˆ†æã€‚

## æ•°æ®é›† 1: {args.file1}
{ctx1.schema_prompt}
{ctx1.stats_text()}
{table1}

## æ•°æ®é›† 2: {args.file2}
{ctx2.schema_prompt}
{ctx2.stats_text()}
{table2}

## è¯·åˆ†æ
1. ğŸ” **ç»“æ„å·®å¼‚** â€” åˆ—åã€ç±»å‹ã€æ•°é‡å¯¹æ¯”
2. ğŸ“Š **æ•°æ®å·®å¼‚** â€” æ•°å€¼èŒƒå›´ã€åˆ†å¸ƒã€è¶‹åŠ¿å¯¹æ¯”
3. ğŸ”— **å…±åŒç‚¹** â€” ç›¸åŒçš„åˆ—ã€å¯å…³è”çš„å­—æ®µ
4. ğŸ’¡ **æ´å¯Ÿ** â€” ä¸¤ä¸ªæ•°æ®é›†ç»“åˆåå¯ä»¥å¾—å‡ºä»€ä¹ˆç»“è®º
5. ğŸ› ï¸ **åˆå¹¶å»ºè®®** â€” å¦‚ä½•åˆå¹¶è¿™ä¸¤ä¸ªæ•°æ®é›†

ç”¨ä¸­æ–‡å›ç­”ï¼Œç”¨ markdown æ ¼å¼ã€‚"""

    print(f"\nğŸ”„ å¯¹æ¯”åˆ†æ: {args.file1} vs {args.file2}")
    print("â•" * 60)
    result = llm_query(prompt, timeout=90)
    print(result)
    print("â•" * 60)

    save_history("compare", f"{args.file1} vs {args.file2}", "compare", result)


def cmd_history(args):
    """Show query history."""
    if not HISTORY_FILE.exists():
        print("ğŸ“­ æš‚æ— å†å²è®°å½•")
        return

    try:
        history = json.loads(HISTORY_FILE.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, IOError):
        print("âŒ å†å²è®°å½•æ–‡ä»¶æŸå")
        return

    if args.clear:
        HISTORY_FILE.unlink()
        print("âœ… å†å²è®°å½•å·²æ¸…é™¤")
        return

    print(f"\nğŸ“œ æŸ¥è¯¢å†å² (æœ€è¿‘ {min(len(history), 20)} æ¡)")
    print("â”€" * 60)
    for entry in history[-20:]:
        ts = entry.get("timestamp", "?")[:19]
        action = entry.get("action", "?")
        file = Path(entry.get("file", "?")).name
        query = entry.get("query", "")[:50]
        emoji = {
            "ask": "â“", "report": "ğŸ“", "clean": "ğŸ§¹", "plot": "ğŸ“Š",
            "query": "ğŸ”", "compare": "ğŸ”„", "diagnose": "ğŸ”¬",
        }.get(action, "ğŸ“Œ")
        print(f"  {emoji} [{ts}] {action} on {file}: {query}")
    print("â”€" * 60)


# ---------------------------------------------------------------------------
# Main CLI
# ---------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(
        prog="csvwise",
        description="ğŸ§  csvwise - AI-Powered CSV Data Analyst",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  csvwise info data.csv                          # æŸ¥çœ‹æ•°æ®æ¦‚è§ˆ + è´¨é‡è¯„åˆ†
  csvwise ask data.csv "å¹³å‡é”€å”®é¢æ˜¯å¤šå°‘?"          # æé—®
  csvwise report data.csv -o report.md            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
  csvwise clean data.csv                          # æ•°æ®æ¸…æ´—å»ºè®®
  csvwise diagnose data.csv                       # AI æ·±åº¦è¯Šæ–­
  csvwise plot data.csv "æŒ‰æœˆä»½çš„é”€å”®è¶‹åŠ¿"          # ç”Ÿæˆå›¾è¡¨
  csvwise query data.csv "é”€å”®é¢ > 10000 çš„è®°å½•"    # SQL å¼æŸ¥è¯¢
  csvwise compare a.csv b.csv                     # å¯¹æ¯”ä¸¤ä¸ªæ•°æ®é›†
  csvwise history                                 # æŸ¥çœ‹å†å²
        """,
    )
    parser.add_argument("--version", action="version", version=f"csvwise {VERSION}")
    parser.add_argument("--verbose", "-v", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")

    sub = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # info
    p_info = sub.add_parser("info", help="æŸ¥çœ‹æ•°æ®é›†æ¦‚è§ˆ + è´¨é‡è¯„åˆ†")
    p_info.add_argument("file", help="CSV æ–‡ä»¶è·¯å¾„")

    # ask
    p_ask = sub.add_parser("ask", help="ç”¨è‡ªç„¶è¯­è¨€æé—®")
    p_ask.add_argument("file", help="CSV æ–‡ä»¶è·¯å¾„")
    p_ask.add_argument("question", help="ä½ çš„é—®é¢˜")

    # report
    p_report = sub.add_parser("report", help="ç”Ÿæˆå…¨é¢åˆ†ææŠ¥å‘Š")
    p_report.add_argument("file", help="CSV æ–‡ä»¶è·¯å¾„")
    p_report.add_argument("-o", "--output", help="ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶")

    # clean
    p_clean = sub.add_parser("clean", help="æ•°æ®æ¸…æ´—å»ºè®®")
    p_clean.add_argument("file", help="CSV æ–‡ä»¶è·¯å¾„")

    # diagnose (NEW)
    p_diagnose = sub.add_parser("diagnose", help="AI æ·±åº¦æ•°æ®è¯Šæ–­")
    p_diagnose.add_argument("file", help="CSV æ–‡ä»¶è·¯å¾„")

    # plot
    p_plot = sub.add_parser("plot", help="ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    p_plot.add_argument("file", help="CSV æ–‡ä»¶è·¯å¾„")
    p_plot.add_argument("description", help="å›¾è¡¨æè¿°")
    p_plot.add_argument("--run", action="store_true", help="è‡ªåŠ¨è¿è¡Œç»˜å›¾è„šæœ¬")

    # query
    p_query = sub.add_parser("query", help="SQL å¼æ•°æ®æŸ¥è¯¢")
    p_query.add_argument("file", help="CSV æ–‡ä»¶è·¯å¾„")
    p_query.add_argument("sql", help="æŸ¥è¯¢æè¿°")

    # compare
    p_compare = sub.add_parser("compare", help="å¯¹æ¯”ä¸¤ä¸ªæ•°æ®é›†")
    p_compare.add_argument("file1", help="ç¬¬ä¸€ä¸ª CSV æ–‡ä»¶")
    p_compare.add_argument("file2", help="ç¬¬äºŒä¸ª CSV æ–‡ä»¶")

    # history
    p_history = sub.add_parser("history", help="æŸ¥çœ‹æŸ¥è¯¢å†å²")
    p_history.add_argument("--clear", action="store_true", help="æ¸…é™¤å†å²è®°å½•")

    args = parser.parse_args()

    # Setup logging
    setup_logging(verbose=getattr(args, "verbose", False))

    if not args.command:
        parser.print_help()
        sys.exit(0)

    commands = {
        "info": cmd_info,
        "ask": cmd_ask,
        "report": cmd_report,
        "clean": cmd_clean,
        "diagnose": cmd_diagnose,
        "plot": cmd_plot,
        "query": cmd_query,
        "compare": cmd_compare,
        "history": cmd_history,
    }

    try:
        commands[args.command](args)
    except KeyboardInterrupt:
        print("\n\nâ¹  å·²å–æ¶ˆ")
        sys.exit(130)
    except Exception as e:
        logger.exception("Unhandled error in command '%s'", args.command)
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
